{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "import pickle\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_doc2vec_file = \"d2v_200vecsize_1mincount_1dm_10epochs.model\"\n",
    "doc2vec = Doc2Vec.load('models/doc2vec/' + best_doc2vec_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec.wv.most_similar(positive=['film'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec.wv.most_similar(positive=['astonishing'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec.wv.most_similar(positive=['actor'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec.wv.most_similar(positive=['thriller'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec.wv.most_similar(positive=['fish'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec.wv.most_similar(positive=['inference'], topn=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec.wv.most_similar(positive=['FABOULOUS'], topn=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docs Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sim = 0\n",
    "idx = 0\n",
    "\n",
    "for i in range(1000):\n",
    "    sim = doc2vec.docvecs.most_similar(positive=[i], topn=5)[0][1]\n",
    "    if sim > max_sim and sim < 0.8:\n",
    "        max_sim = sim\n",
    "        idx = i\n",
    "        \n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec.docvecs.most_similar(positive=[20], topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec.docvecs.most_similar(positive=[98085], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[473]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[80661]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[17691]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = [20, 473, 37232, 98085]\n",
    "for r in rs:\n",
    "    print(reviews[r])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros((4, 4))\n",
    "for i, r in enumerate(rs):\n",
    "    for j, r2 in enumerate(rs):\n",
    "        print(\"Similarity between {} and {}: {}\".format(r, r2, doc2vec.docvecs.similarity(r, r2)))\n",
    "        data[i, j] = doc2vec.docvecs.similarity(r, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "import pylab\n",
    "# data = np.array([[0.99, 0.50, 0.44, 0.39],\n",
    "#         [0.50, 1.00, 0.33, 0.31], \n",
    "#         [0.44, 0.33, 1.00, 0.46], \n",
    "#         [0.39, 0.31, 0.46, 0.99]])\n",
    "ax = sns.heatmap(data, vmin=0, vmax=1, cmap='RdBu_r', annot=True, xticklabels=['A', 'B', 'C', 'D'], yticklabels=['A', 'B', 'C', 'D'])\n",
    "pylab.savefig('plots/docs_similarity_heatmap.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc-Word Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_reviews = [196, 296, 99052, 99021]\n",
    "\n",
    "for r in short_reviews:\n",
    "    print()\n",
    "    print(reviews[r])\n",
    "    print()\n",
    "    docvec = doc2vec.docvecs[r]\n",
    "    print(doc2vec.wv.most_similar(positive=[docvec], topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algebraic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_analogy(word1, word2, word3):\n",
    "    vector = doc2vec.wv[word1] - doc2vec.wv[word2] + doc2vec.wv[word3]\n",
    "    return doc2vec.wv.similar_by_vector(vector, topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_analogy('actor', 'man', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_analogy('film', 'movie', 'horror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_analogy('hero', 'man', 'woman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_analogy('big', 'bigger', 'good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_analogy('worse', 'bad', 'good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_analogy('fast', 'faster', 'slow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_analogy('France', 'Paris', 'Japan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_analogy('France', 'Paris', 'Germany')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Famous People Roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_analogy('Einstein', 'scientist', 'Mozart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_analogy('Einstein', 'scientist', 'Picasso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'datasets/unsup'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = [\n",
    "    'datasets/unsupervised/aclImdb/train/neg',\n",
    "    'datasets/unsupervised/aclImdb/train/pos',\n",
    "    'datasets/unsupervised/aclImdb/train/unsup',\n",
    "    'datasets/unsupervised/aclImdb/test/neg',\n",
    "    'datasets/unsupervised/aclImdb/test/pos'\n",
    "]\n",
    "\n",
    "reviews = []\n",
    "\n",
    "\n",
    "for data_path in data_paths:\n",
    "    for f in sorted(os.listdir(data_path)):\n",
    "        with open(data_path + '/' + f, 'r') as file:\n",
    "            text = file.read()\n",
    "            reviews.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, review in enumerate(reviews[-1000:]):\n",
    "    if len(review) < 250:\n",
    "        print(reviews.index(review))\n",
    "        print(review)\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, review in enumerate(reviews[-2000:]):\n",
    "    if len(review) < 400:\n",
    "        print(reviews.index(review))\n",
    "        print(review)\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[196]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[99021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[99125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec.docvecs.similarity(26, 297)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec.docvecs.similarity(416, 99021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec.docvecs.similarity(416, 99125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec.docvecs.similarity(99021, 99125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec.docvecs.similarity(297, 216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/imdb/imdb_master.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data['review'][:1000])):\n",
    "    if len(data['review'][i]) < 500:\n",
    "        print(i)\n",
    "        print(data['review'][i])\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tknzr = TweetTokenizer()\n",
    "\n",
    "reviews = data['review'][:1000].apply(lambda x: tknzr.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "53, 80, 71 # Bad, Bad, Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = doc2vec.infer_vector(reviews[53])\n",
    "vector2 = doc2vec.infer_vector(reviews[80])\n",
    "vector3 = doc2vec.infer_vector(reviews[71])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec.docvecs.similarity(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"words associated with my research questions\".split()\n",
    "new_vector = doc2vec.infer_vector(token)\n",
    "sims = doc2vec.docvecs.most_similar([new_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l90",
   "language": "python",
   "name": "le90"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
